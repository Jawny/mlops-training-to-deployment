{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zV8XQX9wTfF9"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAV3foLUThWO",
    "outputId": "6bb49279-6455-4c4c-8944-a10a69330777"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR-10 Dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wWKiAG8RTip6"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMbkLO2NTj12",
    "outputId": "3f1c941e-cfd1-469e-f780-613bc93aae8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 18:09:54.311190: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-22 18:09:56.723575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14567 MB memory:  -> device: 0, name: Tesla V100-DGXS-16GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2022-08-22 18:09:56.731918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14634 MB memory:  -> device: 1, name: Tesla V100-DGXS-16GB, pci bus id: 0000:08:00.0, compute capability: 7.0\n",
      "2022-08-22 18:09:56.732666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14634 MB memory:  -> device: 2, name: Tesla V100-DGXS-16GB, pci bus id: 0000:0e:00.0, compute capability: 7.0\n",
      "2022-08-22 18:09:56.733395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14634 MB memory:  -> device: 3, name: Tesla V100-DGXS-16GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Architecture\n",
    "# enable multi-gpu\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)))\n",
    "    model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSSW-iO8URYh",
    "outputId": "7fb7498f-fe59-4c51-d946-c873d078ff42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 18:10:01.685106: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_529\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:4\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 18:10:10.136592: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-08-22 18:10:11.100904: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-08-22 18:10:12.003723: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-08-22 18:10:12.537324: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5007 - accuracy: 0.4522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 18:10:33.857209: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_13228\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:40\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 36s 15ms/step - loss: 1.5007 - accuracy: 0.4522 - val_loss: 1.0841 - val_accuracy: 0.6111\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0893 - accuracy: 0.6147 - val_loss: 0.9394 - val_accuracy: 0.6719\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9410 - accuracy: 0.6676 - val_loss: 0.8526 - val_accuracy: 0.6999\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8565 - accuracy: 0.6995 - val_loss: 0.7587 - val_accuracy: 0.7318\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7940 - accuracy: 0.7203 - val_loss: 0.7700 - val_accuracy: 0.7268\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7443 - accuracy: 0.7390 - val_loss: 0.7404 - val_accuracy: 0.7438\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7038 - accuracy: 0.7525 - val_loss: 0.7074 - val_accuracy: 0.7560\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6732 - accuracy: 0.7658 - val_loss: 0.7256 - val_accuracy: 0.7507\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6495 - accuracy: 0.7730 - val_loss: 0.6863 - val_accuracy: 0.7630\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6158 - accuracy: 0.7826 - val_loss: 0.6770 - val_accuracy: 0.7681\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5973 - accuracy: 0.7879 - val_loss: 0.6688 - val_accuracy: 0.7733\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5755 - accuracy: 0.7974 - val_loss: 0.7042 - val_accuracy: 0.7647\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5554 - accuracy: 0.8035 - val_loss: 0.6463 - val_accuracy: 0.7863\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5363 - accuracy: 0.8109 - val_loss: 0.6666 - val_accuracy: 0.7821\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5291 - accuracy: 0.8136 - val_loss: 0.6510 - val_accuracy: 0.7812\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5092 - accuracy: 0.8195 - val_loss: 0.6556 - val_accuracy: 0.7875\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5041 - accuracy: 0.8214 - val_loss: 0.7238 - val_accuracy: 0.7594\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4814 - accuracy: 0.8286 - val_loss: 0.6726 - val_accuracy: 0.7791\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4799 - accuracy: 0.8322 - val_loss: 0.6566 - val_accuracy: 0.7873\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4633 - accuracy: 0.8353 - val_loss: 0.6550 - val_accuracy: 0.7891\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4557 - accuracy: 0.8396 - val_loss: 0.7067 - val_accuracy: 0.7838\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4469 - accuracy: 0.8413 - val_loss: 0.6665 - val_accuracy: 0.7856\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4349 - accuracy: 0.8481 - val_loss: 0.6839 - val_accuracy: 0.7842\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4326 - accuracy: 0.8475 - val_loss: 0.6574 - val_accuracy: 0.7851\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4258 - accuracy: 0.8505 - val_loss: 0.6722 - val_accuracy: 0.7911\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4272 - accuracy: 0.8503 - val_loss: 0.6576 - val_accuracy: 0.7850\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4124 - accuracy: 0.8570 - val_loss: 0.7326 - val_accuracy: 0.7753\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4099 - accuracy: 0.8575 - val_loss: 0.6872 - val_accuracy: 0.7814\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4043 - accuracy: 0.8590 - val_loss: 0.6726 - val_accuracy: 0.7914\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3983 - accuracy: 0.8591 - val_loss: 0.6901 - val_accuracy: 0.7905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c748e56a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Training\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6-Uf3afRGLeD"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save('/results/cifar_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCN5Ijp1HwmL"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HqyVA_98H48a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:11:27.171879: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-22 19:11:29.406168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14567 MB memory:  -> device: 0, name: Tesla V100-DGXS-16GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2022-08-22 19:11:29.407004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14634 MB memory:  -> device: 1, name: Tesla V100-DGXS-16GB, pci bus id: 0000:08:00.0, compute capability: 7.0\n",
      "2022-08-22 19:11:29.407718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14634 MB memory:  -> device: 2, name: Tesla V100-DGXS-16GB, pci bus id: 0000:0e:00.0, compute capability: 7.0\n",
      "2022-08-22 19:11:29.408407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14634 MB memory:  -> device: 3, name: Tesla V100-DGXS-16GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "# load newly trained model\n",
    "inference_model = load_model(\"/results/cifar_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Plane\", \"Car\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Boat\", \"Truck\"]\n",
    "img = image.load_img(\"/mnt/dataset/validation/frog.jpg\", target_size=(32,32))\n",
    "image_to_test = image.img_to_array(img)/255\n",
    "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
    "results = inference_model.predict(list_of_images)\n",
    "single_result = results[0]\n",
    "most_likely_result = int(np.argmax(single_result))\n",
    "\n",
    "class_likelihood = single_result[most_likely_result]\n",
    "\n",
    "class_label = class_labels[most_likely_result]\n",
    "print(\"This image is a {} - Likelihood {:2f}\".format(class_label, class_likelihood))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
